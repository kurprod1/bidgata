# Arsitektur Pada Big Data

Sebelum mendalami proses Big Data Engineer, alangkah baiknya mendalami arsitektur big data terlebih dahulu. Big Data Engineer diharuskan mempunyai skill untuk membuat arsitektur Big Data agar mempermudah proses pengumpulan data dan proses ETL. Arsitektur Big Data terdiri dari 3 jenis yaitu :

## Arsitektur Batch Processing

Arsitektur Batch Processing adalah arsitektur untuk pengolahan Data secara batch atau terjadwal saja. Berikut adalah arsitektur nya.

![](https://lh5.googleusercontent.com/pgNUsuT_DbePads7AX0bQAgua3GIHD78e0HuPVGOUwfVxGGi7RMBiCCMbokLN9DJteOoDnLw_Nr2JTVDcHIdu2TZL0YrojgM_cJM_Tkb1ipM1hlt05GPa0MoH8xeHidjnDUuDNlFUX1oI0GPcDCmrqY7bjDOUq7mEPGDv-VI0faDWcPWld9Fa0KU)

Penjelasan :

Data Source terdiri dari database dan text file(csv,json) kemudian di upload ke Data Lake(HDFS di Hadoop, atau GCS di Google Cloud). Setelah itu di lakukan proses transformasi data menggunakan tools Apache Spark. Kemudian jika sudah selesai, di simpan di Data Warehouse agar bisa di gunakan untuk membuat Dashboard atau kebutuhan Data Analytics. Semua proses ini di orchestrate atau di proses automation menggunakan tools Apache Airflow. 

## Arsitektur Streaming Processing (Arsitektur Kappa)

Arsitektur Streaming Processing atau disebut juga Arsitektur Kappa untuk pengolahan Data secara Streaming atau Neal Real Time. Berikut adalah arsitektur nya.

![](https://lh6.googleusercontent.com/dHdgkkm3bFXqH8Wk9_uktuZWgBPLbOHcPoUgC10NICVJna7Iq5CS-ppcaN1gxaBZMHMmb9bW8TR88HHIA_nH5eWn7Gt0XdfC8PM7nm1jjc69mZ-2-dtsgcdXuspYG7pFtNf8g6-X-vZcghBMavCB69ZZR4FieVK05J8CjznxXB7wjMZVgewvN471)

Penjelasan :

Data Source terdiri dari database dan text file(csv,json) kemudian di tarik data nya oleh message broker menggunakan tools Apache Kafka. Kemudian data yang ada di message broker di proses oleh streaming engine menggunakan tools Apache Kafka Streams atau Apache Spark Streaming untuk di lakukan proses transformasi data. Jika sudah selesai bisa di gunakan untuk Real Time Dashboard, Data Analytics atau di simpan ke Data Warehouse baik SQL maupun NoSQL.

## Arsitektur Lambda(Batch & Streaming Processing)

Arsitektur Batch & Streaming Processing atau di sebut juga Arsitektur Lambda adalah arsitektur penggabungan Batch dan Streaming Processing. Kebanyakan perusahaan-perusahaan yang produk utama nya berbasis Teknologi seperti Go-Jek, Bukalapak, Tokopedia dst menggunakan arsitektur ini.  Berikut adalah arsitektur nya

![](https://lh5.googleusercontent.com/SmPQ5Y3U8ilQ4yioQHlo0vLJ1RgMnPX9kIJ1jK5Hl7XPsP8i36jTPz6Z3PieusQhW7QdDMq1F3jyZHMfhE7zZ_eEsuO0dJtJWNa2LdxvpbjkUwNCill_w-V77Pzgh32B8dUpczZON5Z2VdaNDLh6UCrIM6JPpYu-cOgyfbbI8P8ltQPS5z2xeUQm)

Penjelasan :

- Data Sources : Bisa berupa Database, File text(csv, json, avro, parquet).

- Data Storage : Data Storage ini di sebut Data Lake. Tools nya HDFS(Hadoop File System) di Hadoop, GCS(Google Cloud Storage) di Google Cloud. 

- Real-Time Message Ingestion : Jika pengolahan data menggunakan metode streaming atau real-time maka di perlukan real-time message ingestion tools untuk menangkap data secara streaming atau real time dan di gunakan untuk proses pengolahan data secara streaming. Tools yang di gunakan adalah Kafka, PubSub(Google Cloud).

- Batch Processing : Pengolahan Data Secara Batch atau terjadwal. Tools nya Apache Spark, Apache Beam.

- Stream Processing : Pengolahan Data Secara Streaming atau Real-Time. Proses ini di gunakan untuk mengolah data dari tools Real-Time Message Ingestion agar datanya tidak ada yang duplikasi, atau problem lain nya sebelum di simpan di Analytical Data Store atau digunakan di untuk keperluan analytics dan reporting.

- Orchestration : adalah proses automation workflow di dalam sebuah proses pengolahan data ETL secara batch. Jadi proses pengolahan data ETL secara batch dilakukan otomatis jalan sesuai jadwal yang di tentukan apakah perjam, perhari, perminggu, perbulan dst. Tools yang digunakan adalah Apache Airflow, Apache Oozie, Luigi, Cron Job.

- Analytical Data Store : Data Warehouse SQL dan NoSQL. Data Warehouse SQL untuk menyimpan data yang terstruktur. Tools Data Warehouse SQL yaitu Apache Hive di Hadoop, BigQuery di Google Cloud, Redshift di Amazon Web Service. Data Warehouse NoSQL untuk menyimpan data yang terstruktur, semi terstruktur(json) dan tidak terstruktur(image, text, video). Tools Data Warehouse NoSQL yaitu Apache HBase dan Apache Cassandra di Hadoop, Bigtable di Google Cloud, MongoDB.

- Analytics And Reporting : Proses yang di lakukan oleh Data Scientist untuk membuat Machine Learning Model serta Data Analyst untuk membuat Reporting dan Dashboard untuk para user.
